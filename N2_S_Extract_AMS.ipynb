{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires station time series and outputs each station AMS \n",
    "in an individual csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_frequency(df, fr, cols):\n",
    "    \"\"\"Create a new df with col aggregated by desired frequency\n",
    "    Note: df needs to have a column named \"date\" and be a datetime object\n",
    "    in order to work. Available freq depending on frequency of the original data\n",
    "    possible values of freq: \"3h, 6h, 12h, 24h...\" and so on. It is not limited\n",
    "    to hours but can also aggregate by week or by month (e.g. \"Jan\"), by year (e.g. \"A\" for\n",
    "    annual) too.\"\"\"\n",
    "\n",
    "    return df.groupby(pd.Grouper(key='date', freq=fr))[cols].max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st_records in glob.glob(\"station_data/ts/*\"):\n",
    "    print(st_records)\n",
    "    name = st_records.split('/')[-1]\n",
    "    df = pd.read_csv(st_records, parse_dates=['Unnamed: 0'], na_values=\"M\")\n",
    "    df.columns = ['date', 'prcp']\n",
    "    df.replace(\"T\", 0.00, inplace=True)\n",
    "    df.prcp = df.prcp.astype(np.float)\n",
    "    if not os.path.isdir(\"station_data/ams\"):\n",
    "        os.makedirs(\"station_data/ams\")\n",
    "    pd.DataFrame(aggregate_by_frequency(df, 'A', 'prcp')).to_csv(\"station_data/ams/{}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.date_range(start=pd.to_datetime(\"1890-12-31\"), \n",
    "                                end=pd.to_datetime(\"2019-12-31\"), freq=\"A\"))\n",
    "df.columns=['date']\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This for loop is for merging all the station AMS into a single csv file\n",
    "organized by rows --> years, and columns --> stations.\n",
    "\"\"\"\n",
    "\n",
    "cols = []\n",
    "for f in glob.glob(\"input/station_data/ams/*\"):\n",
    "    cols.append(f.split('/')[-1][:-4])\n",
    "   # print(cols)\n",
    "    df_join = pd.read_csv(f, parse_dates=['date'], index_col=0)\n",
    "    df = df.join(df_join)\n",
    "    df.columns = cols\n",
    "\n",
    "# Save complete AMS for all stations    \n",
    "df.to_csv(\"station_data/ams_all_stations.csv\")\n",
    "\n",
    "#Only save the historical period that we decided on:\n",
    "df['1950':'2000'].to_csv(\"station_data/ams_all_stations_1950_2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
