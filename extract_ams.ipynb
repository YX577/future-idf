{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name: extract_ams\n",
    "Author: Tania Lopez-Cantu\n",
    "Date: 06/13/2020\n",
    "-------------------------\n",
    "The following notebook writes into a csv file the AMS at each gridcell of a gridded \n",
    "dataset using the grid ids that we stored and created using the extract_grid_center_indices\n",
    "notebook.\n",
    "\n",
    "CSV format: rows: year; columns: grid cell id\n",
    "\"\"\"\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variables to modify:\n",
    "file_path --> path to .nc file \n",
    "save_path --> directory where to store the output of this notebook\n",
    "grid_info --> path to csv with grid_id info was stored\n",
    "\"\"\"\n",
    "file_path = \"cheswx_prcp_1948_2015.experimental.2017-08-14.nc\"\n",
    "save_path = \"output/\"\n",
    "grid_info = \"output/historical_ches_gridcells.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_frequency(df, fr, cols):\n",
    "    \"\"\"Create a new df with col aggregated by desired frequency\n",
    "    Note: df needs to have a column named \"date\" and be a datetime object\n",
    "    in order to work. Available freq depending on frequency of the original data\n",
    "    possible values of freq: \"3h, 6h, 12h, 24h...\" and so on. It is not limited\n",
    "    to hours but can also aggregate by week or by month, by year too.\"\"\"\n",
    "\n",
    "    return df.groupby(pd.Grouper(key='date', freq=fr))[cols].max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamps(nc_file, origin):\n",
    "    \"\"\"\n",
    "    This function outputs a timestamp series using the Time variable from the ncfile, and its origin\n",
    "    ---\n",
    "    input: .nc file\n",
    "    output: [array] timestamps starting from the .nc file Time variable origin\n",
    "    \"\"\"\n",
    "    timev = nc_file.variables['time'][:]\n",
    "\n",
    "    return pd.to_datetime(timev, unit=\"h\", origin=pd.Timestamp(origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_ids = pd.read_csv(grid_info, usecols=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"cheswx_prcp_1948_2015.experimental.2017-08-14.nc\"\n",
    "nc_file = Dataset(file_path, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units\n",
      "Time: hours since 1948-01-01\n",
      "Precipitation: mm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Verify time and precipitation variables and their units in the\n",
    "nc file\n",
    "\"\"\"\n",
    "\n",
    "print(\"Time: {}\".format(nc_file.variables[\"time\"].units))\n",
    "print(\"Precipitation: {}\".format(nc_file.variables[\"prcp\"].units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timestamps\n",
    "origin = nc_file.variables[\"time\"].units.split(\" \")[-1]\n",
    "timestamps = get_timestamps(nc_file, origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1948-01-01 07:00:00', '1948-01-02 07:00:00',\n",
       "               '1948-01-03 07:00:00', '1948-01-04 07:00:00',\n",
       "               '1948-01-05 07:00:00', '1948-01-06 07:00:00',\n",
       "               '1948-01-07 07:00:00', '1948-01-08 07:00:00',\n",
       "               '1948-01-09 07:00:00', '1948-01-10 07:00:00',\n",
       "               ...\n",
       "               '2015-12-22 07:00:00', '2015-12-23 07:00:00',\n",
       "               '2015-12-24 07:00:00', '2015-12-25 07:00:00',\n",
       "               '2015-12-26 07:00:00', '2015-12-27 07:00:00',\n",
       "               '2015-12-28 07:00:00', '2015-12-29 07:00:00',\n",
       "               '2015-12-30 07:00:00', '2015-12-31 07:00:00'],\n",
       "              dtype='datetime64[ns]', length=24837, freq=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take some time because the matrix is (24837, 222, 207)\n",
    "prcp = np.ma.getdata(nc_file.variables[\"prcp\"])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ids.iloc[0,0].lstrip(\"id_\").split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data to create df\n",
    "r = {}\n",
    "for grid_id in df_grid_ids['grid_id'].values:\n",
    "    indeces = grid_id.lstrip(\"id_\").split(\"_\")\n",
    "    gridiy = int(indeces[0]) #lat\n",
    "    gridix = int(indeces[1]) #lon\n",
    "    r[grid_id] = np.ma.getdata(prcp[:, gridiy, gridix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of all precipitation records. This might take some time.\n",
    "full_domain = pd.DataFrame(r)\n",
    "cols = full_domain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time stamps that we extracted earlier\n",
    "full_domain['date'] = timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AMS using function defined at the start of this notebook.\n",
    "# This might take some time.\n",
    "\n",
    "df_ams = aggregate_by_frequency(full_domain, 'A', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_AMS to path specified at the beginning of notebook\n",
    "name_csv = \"historical_ches_AMS\"\n",
    "df_ams.to_csv(f\"{save_path}{name_csv}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}